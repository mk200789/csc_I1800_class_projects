from numpy import dot, array, random, concatenate, asarray, array_equal, subtract
import itertools

def extractData():
	#Returns a list of input letters and its corresponding output and the character
	input_raw_bipolar_vals = []
	temp = []

	file = open('input.txt', 'r')

	for char in file.read():
		if char == "\n":
			pass
		#if char == "a" or char == "b" or char == "c" or char == "e" or char == "j" or char == "k":
		if char == "a":
			input_raw_bipolar_vals.append((array(temp), array([1, -1, -1, -1 ,-1 ,-1, -1]), char))
			temp = []
		if char == "b":
			input_raw_bipolar_vals.append((array(temp), array([-1, 1, -1, -1 ,-1 ,-1, -1]), char))
			temp = []
		if char == "c":
			input_raw_bipolar_vals.append((array(temp), array([-1, -1, 1, -1 ,-1 ,-1, -1]), char))
			temp = []
		if char == "d":
			input_raw_bipolar_vals.append((array(temp), array([-1, -1, -1, 1 ,-1 ,-1, -1]), char))
			temp = []
		if char == "e":
			input_raw_bipolar_vals.append((array(temp), array([-1, -1, -1, -1, 1, -1, -1]), char))
			temp = []
		if char == "j":
			input_raw_bipolar_vals.append((array(temp), array([-1, -1, -1, -1 ,-1 , 1, -1]), char))
			temp = []
		if char == "k":
			input_raw_bipolar_vals.append((array(temp), array([-1, -1, -1, -1 , -1, -1, 1]), char))
			temp = []
		if char == "_":
			temp.append(-1)
		if char == "x":
			temp.append(1)

	return input_raw_bipolar_vals

def initiateRandomWeights(num_letters):
	#Returns a matrix containing random weights for corresponding letters
	weights = []
	for j in range(num_letters):
		temp = []
		for i in range(63):
			temp.append(random.random())
		weights.append(temp)

	#return weights
	return [[0.45964223788566283, 0.7438684700083301, 0.01419097090501753, 0.16253784113837266, 0.6035847710835792, 0.5142340269495733, 0.1502597970507511, 0.09403096459258253, 0.31412992163718445, 0.6117365544724734, 0.38592709890781995, 0.8749534045535612, 0.6164900515839506, 0.9114507224308523, 0.39092601678115746, 0.44339344130919356, 0.7517181491949502, 0.6979353612900998, 0.970031051520059, 0.5203416791618557, 0.24857227022220807, 0.8579315763246633, 0.6948275218885401, 0.2180831287668168, 0.2396146217283005, 0.6344470695554214, 0.2503929437868013, 0.0730853039897984, 0.20634499865304679, 0.8421939748895273, 0.0315643327869648, 0.20339013601043476, 0.7718546551215472, 0.7203675588820115, 0.4415426603638761, 0.5413652002718911, 0.28330027813189496, 0.6851939034791154, 0.07998187783338595, 0.13402366392898224, 0.2107479640814629, 0.20756483152370808, 0.0533806643434348, 0.004085519233329893, 0.9831531727161544, 0.4294599288709777, 0.18600050081621866, 0.02583983548449531, 0.18075453480183845, 0.4188103421108239, 0.29435990812469925, 0.831205629157296, 0.3492883396974539, 0.21947415654092706, 0.9375087335003407, 0.5177310042444702, 0.37074343394076903, 0.2421371368387134, 0.8374415035550579, 0.5567261705183786, 0.2086762319492078, 0.9588505093846869, 0.19930350933990093], [0.0642485770249186, 0.5053195522708571, 0.23889262600653183, 0.9100584216292453, 0.28888039999319204, 0.7604731261893924, 0.2933999476469409, 0.2590506732527762, 0.18652462209436094, 0.4950152094805962, 0.7213937325998561, 0.14117920159755049, 0.9056129370997786, 0.9436195767422871, 0.21353448826170773, 0.13282431856777444, 0.4849644212979026, 0.43408176107696017, 0.6971227928424643, 0.20211355648563778, 0.8199126286083848, 0.8989727087915982, 0.3840858531201742, 0.5349374262965986, 0.14829144784924375, 0.3747640111468544, 0.4119555554209203, 0.9639358634855665, 0.17943060090684715, 0.8598504436788585, 0.5353387754405959, 0.3812956245113497, 0.9689551745290124, 0.6950471428165493, 0.8801560264215695, 0.11019864603737428, 0.4491971631198751, 0.13247033699386335, 0.8914592759413134, 0.9460396013383623, 0.08924120295716309, 0.13662296846579847, 0.538372702854762, 0.8687924009313077, 0.5660702556995963, 0.2156322306464009, 0.3675581879510209, 0.23617111700500482, 0.09554388392463042, 0.5860437999412086, 0.43311579089349317, 0.1488013995039017, 0.7671125861473495, 0.44663705336180914, 0.3930999582393613, 0.12347626634454656, 0.9709381730259311, 0.20236316053131853, 0.930758728115198, 0.6840834365245579, 0.9825367496832925, 0.12896977653716568, 0.9988454708478248], [0.6063816727320428, 0.9487460894445433, 0.5363775497354482, 0.29636816486432216, 0.659173080696896, 0.7488701205162086, 0.08400373235237601, 0.8316421262927807, 0.12156437354610794, 0.2802817622664767, 0.7353238754658622, 0.7325045616229389, 0.4702858812638486, 0.29229618493459897, 0.11833110415730008, 0.8574683217644061, 0.8371002696154324, 0.19246363465094307, 0.14430374490981934, 0.5094946893326685, 0.3649746252496746, 0.7065778476569694, 0.3793936018891757, 0.5342797039319072, 0.48043178931788655, 0.8649559667438411, 0.2581643524105851, 0.5803968218256585, 0.21421400386344536, 0.5515496678564826, 0.8675341413549909, 0.9551096519218819, 0.37469525232658374, 0.3894260943140211, 0.3103630991402533, 0.04378044420134597, 0.9751349812189423, 0.6474798767612033, 0.29037753831472946, 0.1328762261411236, 0.07332281024026066, 0.877292048148901, 0.9429834282332549, 0.7127995364148411, 0.3177058105311842, 0.14465599971554133, 0.9981543755601315, 0.14503176753680913, 0.4035173314534485, 0.38791719279470827, 0.5254230501902574, 0.11552198710315353, 0.06753364612939983, 0.23229648250188195, 0.7050289866711863, 0.21832539851343846, 0.4012035971280159, 0.016560918430483462, 0.5476047657580383, 0.9701322178299099, 0.04173038020533393, 0.4951572083192691, 0.27863816206741676], [0.6062864732919129, 0.6847402637125322, 0.7139223493215315, 0.28917288970203026, 0.28822836196665624, 0.11827528756727201, 0.6457422475239638, 0.5566454663914301, 0.11648503931005671, 0.0916161130719857, 0.6827940583207825, 0.23718505719722605, 0.3470629533921421, 0.617141394303108, 0.4025606296912936, 0.866057565052699, 0.7633371769789287, 0.2840552706716071, 0.19209546279440393, 0.29552293192570045, 0.8781711338201177, 0.40529308845969614, 0.9113085192075188, 0.7686277867403818, 0.18134725640676808, 0.8860247808973111, 0.8133742122530756, 0.18658131916245912, 0.4117569014393132, 0.7246362157138403, 0.3207172298794696, 0.9203104370376299, 0.5271765250013235, 0.00024353643491459298, 0.20068641848565816, 0.4614146837185048, 0.48063013529492216, 0.3180850315332353, 0.0754884516109392, 0.2435911478368854, 0.8138927606301142, 0.2823498562905218, 0.04758962177513293, 0.22495826101815541, 0.5427456400721878, 0.7700114787584084, 0.04109056955923418, 0.5613256469734825, 0.7972444332325876, 0.22017154294142038, 0.5956788185433057, 0.8535910270611857, 0.6417630359611151, 0.946600418664711, 0.20758477600864245, 0.6154961176835776, 0.5687912388636119, 0.8564918900389765, 0.9721939511907107, 0.8321774265186642, 0.8778336823197243, 0.42370063360172106, 0.2669583133406831], [0.09953370534901407, 0.08936734144638203, 0.28926551000335843, 0.7918956298848394, 0.8332881216769407, 0.6159443030347839, 0.008629296474171988, 0.28544336038338813, 0.7323594782299157, 0.1008884633701459, 0.7493119382322115, 0.7588442706699655, 0.9226867798874108, 0.4332336309790037, 0.22742235990311588, 0.289792808892281, 0.7053114898038427, 0.8072412338272392, 0.8784289095349187, 0.503560590655793, 0.19646902531299426, 0.1752669611778095, 0.03893521194476868, 0.02846914199662831, 0.006657213604064682, 0.888451669263458, 0.901329540276293, 0.39050490246094083, 0.4564804516698179, 0.5155632515001572, 0.24419317326377632, 0.9058790935094154, 0.011687647909185639, 0.37859128576059276, 0.4128935730620441, 0.32001438976189645, 0.7843933034136409, 0.23373805122017377, 0.7214959019423725, 0.3415973412734099, 0.5399600115695108, 0.5174460566447143, 0.3341767752670626, 0.1799602611944625, 0.8549433653809322, 0.5220784806025129, 0.6300006891999127, 0.8075946437764506, 0.6499208635585625, 0.36419506659420264, 0.6583858730100357, 0.7441038909053777, 0.8936228755266231, 0.28595345311422715, 0.7103962879335399, 0.3117029054245557, 0.927376477881097, 0.22360530429768788, 0.11103324898695055, 0.7070255213091384, 0.7563783668781224, 0.9152844976025609, 0.5291034220871157], [0.9396566725739011, 0.7298772394066401, 0.9086097585360129, 0.5155010675169465, 0.7385155378451493, 0.758871406000114, 0.9925306231872639, 0.7533804534163129, 0.29472365350611796, 0.5429905665223026, 0.5598711456381826, 0.48278046288194865, 0.24564363880737028, 0.4227790440314141, 0.7126108378602252, 0.9554268782026342, 0.9798057754748644, 0.3956336202084384, 0.4092474711691453, 0.35780673214662495, 0.8252529087606159, 0.744289516312839, 0.7568089892751807, 0.37073773763952367, 0.37003534976678365, 0.6026252808867949, 0.6037592288571569, 0.1591736504156549, 0.8109079010275143, 0.5835056133830766, 0.746481450263152, 0.9789835320725584, 0.9205408974665001, 0.28148531298130774, 0.6946153072778094, 0.6596951145251986, 0.29383248908694537, 0.38958566859452337, 0.2382325566636132, 0.43506537685186153, 0.757082122344402, 0.32691693887943396, 0.5378496956981896, 0.0018141244881588747, 0.8183511498506276, 0.5402701250169782, 0.8560369439547509, 0.9357438694478445, 0.22269870176437334, 0.25286947423607486, 0.19602066631709825, 0.35544265341031966, 0.7539391523232062, 0.4857742616916326, 0.10391952134742255, 0.5712731742154882, 0.05052840744337028, 0.735189502760353, 0.05789963917048779, 0.3012218719901075, 0.6847115066298017, 0.3484894955406107, 0.6784131799881838], [0.07339203519730697, 0.962454661229592, 0.8147987059594551, 0.8290527163653261, 0.4960780569107007, 0.15881857573161906, 0.9503458828984338, 0.12794585578298612, 0.10059134450826801, 0.23519544578441542, 0.04484846352517302, 0.8083389838210631, 0.10713561127970495, 0.716764108282597, 0.19797577117183118, 0.694594303952375, 0.5318706298260466, 0.45473745580672476, 0.7952822011272243, 0.28198827996847475, 0.24676111817750657, 0.9742864188422881, 0.50980241632294, 0.5458553705287906, 0.8887276677656802, 0.5357447314097628, 0.1752875819371258, 0.2546894855266584, 0.09514066298183477, 0.8194562390785657, 0.6129356350107448, 0.9752847802646755, 0.46058140880588316, 0.21884775184618022, 0.36980197747133614, 0.9145727707011597, 0.8595967988272983, 0.22688673192541764, 0.8295528990614147, 0.061845556570329974, 0.413337656517477, 0.8695628434692051, 0.9437102852868724, 0.02203480871188135, 0.8874471101428361, 0.31107244546625723, 0.28675893665251806, 0.700811314687398, 0.39262014557121716, 0.3418239123079828, 0.06936038701381508, 0.5932627955869315, 0.08947025918570062, 0.22809539818977065, 0.17157594921500396, 0.9792982614096246, 0.4511444883618162, 0.28769282114776384, 0.24794858069079573, 0.07121251298740539, 0.6215163283203345, 0.49015071870944293, 0.6056351431307393]]

#output = lambda y: -1 if y < 0 else 1

def output(y, target):
	if y < 0:
		return array([-1, -1, -1, -1, -1, -1, -1])
	else:
		return target

def training(training_set, weight, alpha):
	iterations = 0


	while(1):
		error_count = 0
		iterations += 1

		for i in range(len(training_set)):

			target = training_set[i][1]

			xw = dot(training_set[i][0], weight[i])
			y_in = output(xw, target)


			if not array_equal(array(target-y_in), array([0,0,0,0,0,0,0])):
				#update weights
				#weight[i] = weight[i] + alpha*(target-y_in) * training_set[i][0]
				weight[i] = weight[i] + alpha *2 * training_set[i][0]
				error_count += 1


		if error_count == 0:
			break
	
	return weight, iterations


	

if __name__ == '__main__':
	#get the training data
	training_data = extractData()

	#get the weights for the data
	weights = initiateRandomWeights(7)

	#print "Initial weights: ", weights

	final_weights, iterations = training(training_data, weights, 0.1)

	#print "Final weights: ", final_weights
	
	print "iterations: ", iterations


